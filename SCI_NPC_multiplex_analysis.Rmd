---
title: "Neural Progenitor Cells for Treatment of Spinal Cord Injury"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r echo=FALSE, warning=FALSE, error=FALSE, message=FALSE}
#1. INSTALLING PACKAGES
#install.packages("ggplot2")
#install.packages("data.table")
#install.packages("RColorBrewer")
#install.packages("cowplot")

#2. ATTACHING PACKAGES
library(ggplot2)
library(data.table)
library(RColorBrewer)
library(cowplot)
library(knitr)
```

```{r echo=FALSE, warning=FALSE, error=FALSE, message=FALSE}
#1. IMPORTING DATA
DT = fread("SCI_NPC_saline_overtime_data.csv")

#2. CLEANING COLUMN NAMES
column_name_adjuster <- function(column_name_raw){
    column_name_adjusted <- substr(column_name_raw, 4, nchar(column_name_raw))
    column_name_adjusted <- substr(column_name_adjusted, 0, nchar(column_name_adjusted)-5)
    return(column_name_adjusted)
}

col_name_subset <- names(DT[,!c("SCI", "treatment", "evaluation", "evaluation_weeks")])   
col_name_subset <- unlist(lapply(col_name_subset, function(col_name){column_name_adjuster(col_name)}))
names(DT) <-  c("SCI", "treatment", "evaluation", "evaluation_weeks", col_name_subset)

#3. REMOVING UNNECESSARY DATA
DT <-  DT[!is.na(evaluation_weeks)]
DT[, "evaluation"] = NULL

#4. LONG FORMAT
DT_melt <- melt.data.table(DT, id.vars=c("SCI", "treatment", "evaluation_weeks"))

#5. NORMALIZE TO HEALTHY FOR EACH TARGET SEPARATELY
expression_normalizer <-  function(list_object){
  divisor <-  list_object[treatment=="none", mean(value)]
  list_object[, norm_value:=value/divisor]
  return(list_object)
}

DT_melt <- do.call(rbind, lapply(split(DT_melt, DT_melt[,variable]), function(object){expression_normalizer(object)}))

#6. REMOVING UNNECESSARY DATA & ADJUSTING VARIABLE TYPES
DT_melt[, "SCI"] = NULL
DT_melt <- DT_melt[treatment!="none"]
DT_melt[, "treatment"] <- factor(DT_melt[, treatment])
```

```{r echo=FALSE, warning=FALSE, error=FALSE, message=FALSE}
#1. Summarizing data per treatment, time point and target
DT_summary <- DT_melt[, .(norm_value = mean(norm_value), norm_value_sd = sd(norm_value), n=.N), by=c("treatment", "evaluation_weeks", "variable")]
DT_summary <- DT_summary[,`:=`(SEMx1.96=qnorm(0.975)*norm_value_sd/sqrt(n))][, `:=`(CI.lower = norm_value-SEMx1.96, CI.upper=norm_value+SEMx1.96)]
```

```{r echo=FALSE, warning=FALSE, error=FALSE, message=FALSE}
################################################################### STATISTICAL ANALYSIS ##############################################################
```

```{r echo=FALSE, warning=FALSE, error=FALSE, message=FALSE}
#1. Evaluating assumption of normal distribution
norm_test_p <- do.call(rbind, lapply(split(DT_melt, DT_melt[,.(treatment, evaluation_weeks, variable)]), function(subset){subset[,p_value:=shapiro.test(subset[, norm_value])[2]]}))
norm_test_p <- norm_test_p[, .(p_value= mean(p_value)), by=c("treatment", "evaluation_weeks", "variable")]
#2. Evaluating assumption of homogenity of variances between treatments within time points
homo_test_p <- do.call(rbind, lapply(split(DT_melt, DT_melt[, .(evaluation_weeks, variable)]), function(subset){subset[,p_value:=fligner.test(subset$norm_value, subset$treatment)[3]]}))
homo_test_p <- homo_test_p[, .(p_value=mean(p_value)), by=c("evaluation_weeks", "variable")]
#3. Independent two group comparison 
setkey(homo_test_p, "evaluation_weeks", "variable")
setkey(norm_test_p, "evaluation_weeks", "variable", "treatment")

two_group_test <- function(list_object){
  week = list_object[, evaluation_weeks][1]
  target = list_object[, variable][1]
  
  norm_assump_1 = FALSE
  norm_assump_2 = FALSE
  homo_assump = FALSE
  #Checking for fulfillment of assumptions
  if(homo_test_p[.(week, target), p_value]>0.05){
    homo_assump = TRUE
  }
  
  if(norm_test_p[.(week, target, "NPC"), p_value]>0.05){
    norm_assump_1 = TRUE
  }
  
  if(norm_test_p[.(week, target, "saline"), p_value]>0.05){
    norm_assump_2 = TRUE
  }
  
  if(isTRUE(norm_assump_1) & isTRUE(norm_assump_2)){
    if(isTRUE(homo_assump)){
      p_value_out <- t.test(list_object[treatment=="saline", norm_value], list_object[treatment=="NPC", norm_value], var.equal = TRUE)$p.value 
      return(data.table(evaluation_week=week, variable=target, p_value=p_value_out, test="t.test_equal_var"))
    } else {
      p_value_out <- t.test(list_object[treatment=="saline", norm_value], list_object[treatment=="NPC", norm_value], var.equal = FALSE)$p.value 
      return(data.table(evaluation_week=week, variable=target, p_value=p_value_out, test="t.test_unequal_var"))
    }
  } else {
    p_value_out <- wilcox.test(list_object[treatment=="saline", norm_value], list_object[treatment=="NPC", norm_value])$p.value 
    return(data.table(evaluation_week=week, variable=target, p_value = p_value_out, test="wilcox_test"))
  }
}

group_comparison_p <- do.call(rbind, lapply(split(DT_melt, DT_melt[, .(variable, evaluation_weeks)]), function(subset){two_group_test(subset)}))
```

```{r echo=FALSE, warning=FALSE, error=FALSE, message=FALSE}
#Plotting individual targets
individual_target_plot <- function(target){
  plot_data <- DT_melt[variable==target]
  plot_data_summary <-  DT_summary[variable==target]
  p_value_data <-  group_comparison_p[variable==target]
  
  out_plot <- ggplot(plot_data_summary, aes(x=evaluation_weeks, y=norm_value, color=treatment))+
    #Main
    geom_errorbar(aes(ymin=CI.lower, ymax=CI.upper), size=3, width=1, position = position_dodge(width = 1), alpha=0.8, show.legend = FALSE)+
    geom_jitter(plot_data, mapping=aes(x=evaluation_weeks, y=norm_value, color=treatment), size=5, position = position_jitterdodge(jitter.width = 0.2, dodge.width = 1), alpha=0.7)+
    geom_point(shape = 15, size=8, position = position_dodge(width=1), show.legend = FALSE)+
    #Labels
    xlab("Weeks (Post SCI)")+
    ylab("Normalised expression")+
    scale_x_continuous(breaks=seq(0,12,1))+
    scale_y_continuous(breaks=seq(0,20,2), limits = c(-5, 20))+
    theme(axis.title = element_text(size=20, face="bold"), legend.position = "bottom", legend.justification = "center", legend.text = element_text(size=18), legend.title = element_text(size=18), axis.text = element_text(size=16), axis.line.y = element_blank())+
    #Colors
    scale_color_manual(values=brewer.pal(3, "Set1"), name="Treatment:", labels=c("SCI+NPC", "SCI+Saline"))+
    #Annotations
    annotate(geom="text", label=target, x=6.5, y=7.5, size=14, fontface=2, alpha=0.8)+
    annotate(geom="text",label=paste("p:", toString(format(p_value_data[, p_value][1], digits=2, nsmall = 2)), sep = ""), x=2, y=-4, fontface=4, size=5)+
    annotate(geom="text",label=paste("p:", toString(format(p_value_data[, p_value][2], digits=2, nsmall = 2)), sep = ""), x=5, y=-4, fontface=4, size=5)+
    annotate(geom="text",label=paste("p:", toString(format(p_value_data[, p_value][3], digits=2, nsmall = 2)), sep = ""), x=12, y=-4, fontface=4, size=5)
  
  return(out_plot)  
}
```

```{r echo=FALSE, warning=FALSE, error=FALSE, message=FALSE}
################################################################### OUTPUT ##############################################################
```
##Statistical analysis: between groups for each time point

###Evaluation of assumptions
Assumption of normality is evaluated using Shapiro Wilk's test for each treatment (group) within each time point and for each target separately. Null hypothesis is that data is normally distributed. 

Assumption of homogenity of variances is between the two treatments (groups) within each time point and for each target. Given that both groups followed a normal distribution the homogenity of variances was evaluated using Bartlett's test. Given that at least one of the groups did not follow a normal distribution the homogenity of variances was evaluated using Fligner Killeen's test.  

###Independent two group comparison
Given that data in both treatments (groups) was normally distributed and the variances were equal the groups were compared using two-sided non-paired Student's t-test. Given that data in both treatments (groups) was normally distributed but the groups and unequal variances the variance was estimated separately for eah group and the Welch modification to the degrees of freedom was used. 

Given that data in at least one of the groups was not normally distributed a two-sided non-paired Wilcoxon Rank Sum test with continuity correction in the normal approximation for the p-value was calculated. 

```{r echo=FALSE, warning=FALSE, error=FALSE, message=FALSE}
p_table <- group_comparison_p
p_table[, "p_value"] <- p_table[, format(p_value, digits = 2)]
p_table[, "test"] = NULL
p_table <- dcast.data.table(p_table, ...~evaluation_week, value.var = "p_value")

kable(p_table, align="c", col.names = c("Target", "P-value(2w)", "P-value(5w)", "P-value(12w)"))
```

```{r echo=FALSE, warning=FALSE, error=FALSE, message=FALSE, fig.width=20, fig.height=10}
plot_grid(individual_target_plot("IL-1a"), individual_target_plot("IL-1b"), individual_target_plot("IL-2"), individual_target_plot("IL-4"))
plot_grid(individual_target_plot("IL-6"), individual_target_plot("IL-7"), individual_target_plot("IL-10"), individual_target_plot("IL-12(p70)"))
plot_grid(individual_target_plot("IL-13"), individual_target_plot("IL-17"), individual_target_plot("IL-18"), individual_target_plot("G-CSF"))
plot_grid(individual_target_plot("GM-CSF"), individual_target_plot("GRO/KC"), individual_target_plot("IFN-g"), individual_target_plot("M-CSF"))
plot_grid(individual_target_plot("MCP-1"), individual_target_plot("MIP-1a"), individual_target_plot("MIP-3a"), individual_target_plot("RANTES"))
plot_grid(individual_target_plot("TNFa"), individual_target_plot("VEGF"))
```
